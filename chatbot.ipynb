{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eebbc531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerías importadas. ¡Entorno listo con 6 núcleos disponibles!\n",
      "Metadatos cargados y procesados.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Año de publicación</th>\n",
       "      <th>Código sugerido</th>\n",
       "      <th>Nombre del archivo</th>\n",
       "      <th>Título del estudio</th>\n",
       "      <th>Categoría</th>\n",
       "      <th>Tipo de documento</th>\n",
       "      <th>Subcategoría</th>\n",
       "      <th>Idioma</th>\n",
       "      <th>Número de páginas</th>\n",
       "      <th>Incorpora perspectiva de género</th>\n",
       "      <th>...</th>\n",
       "      <th>Entidad solicitante</th>\n",
       "      <th>Entidad a cargo del estudio</th>\n",
       "      <th>Investigador u organismo principal</th>\n",
       "      <th>Equipo de investigación</th>\n",
       "      <th>Número de documento administrativo</th>\n",
       "      <th>Tipo de financiamiento</th>\n",
       "      <th>Costo del estudio</th>\n",
       "      <th>Base de datos enviada</th>\n",
       "      <th>Base pública</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999</td>\n",
       "      <td>E99-0000</td>\n",
       "      <td>Mercado Laboral en Docencia</td>\n",
       "      <td>Análisis del Mercado de Servicios de Docencia ...</td>\n",
       "      <td>Estudios</td>\n",
       "      <td>Informe</td>\n",
       "      <td>Docentes</td>\n",
       "      <td>Español</td>\n",
       "      <td>123</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Ministerio de Educación de Chile; MINEDUC</td>\n",
       "      <td>Facultad de Ciencias Económicas y Administrati...</td>\n",
       "      <td>Bravo, David</td>\n",
       "      <td>Ruiz-Tagle, Jaime; Sanhueza, Ricardo</td>\n",
       "      <td>Sin información</td>\n",
       "      <td>Interno</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>https://bibliotecadigital.mineduc.cl/bitstream...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>E00-0001</td>\n",
       "      <td>Evaluación Resultados ENLACES</td>\n",
       "      <td>Diseño de un modelo de evaluación de resultado...</td>\n",
       "      <td>Estudios</td>\n",
       "      <td>Informe</td>\n",
       "      <td>TIC</td>\n",
       "      <td>Español</td>\n",
       "      <td>53</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Enlaces; Ministerio de Educación de Chile; MIN...</td>\n",
       "      <td>Asesorías para el Desarrollo</td>\n",
       "      <td>Raczynski, Dagmar</td>\n",
       "      <td>Pavez, M. Angélica</td>\n",
       "      <td>Sin información</td>\n",
       "      <td>Interno</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>https://bibliotecadigital.mineduc.cl/bitstream...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001</td>\n",
       "      <td>E01-0001</td>\n",
       "      <td>Focalización Becas Liceos Para Todos CC</td>\n",
       "      <td>Focalización de Becas del Programa Liceo para ...</td>\n",
       "      <td>Estudios</td>\n",
       "      <td>Informe</td>\n",
       "      <td>Monitoreo y evaluación</td>\n",
       "      <td>Español</td>\n",
       "      <td>30</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Ministerio de Educación de Chile; MINEDUC</td>\n",
       "      <td>Departamento de Salud Pública, PUC</td>\n",
       "      <td>Marshall, Guillermo</td>\n",
       "      <td>Correa, Lorena</td>\n",
       "      <td>Sin información</td>\n",
       "      <td>Interno</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>https://bibliotecadigital.mineduc.cl/bitstream...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>E01-0002</td>\n",
       "      <td>Focalización Becas Liceos Para Todos ECO</td>\n",
       "      <td>Focalización de Becas del Programa Liceo para ...</td>\n",
       "      <td>Estudios</td>\n",
       "      <td>Informe</td>\n",
       "      <td>Monitoreo y evaluación</td>\n",
       "      <td>Español</td>\n",
       "      <td>61</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Ministerio de Educación de Chile; MINEDUC</td>\n",
       "      <td>Departamento de Salud Pública, PUC</td>\n",
       "      <td>Marshall, Guillermo</td>\n",
       "      <td>Correa, Lorena</td>\n",
       "      <td>Sin información</td>\n",
       "      <td>Interno</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>https://bibliotecadigital.mineduc.cl/bitstream...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001</td>\n",
       "      <td>E01-0003</td>\n",
       "      <td>OFT Educación Media</td>\n",
       "      <td>Objetivos Fundamentales Transversales en la En...</td>\n",
       "      <td>Estudios</td>\n",
       "      <td>Informe</td>\n",
       "      <td>Currículo</td>\n",
       "      <td>Español</td>\n",
       "      <td>61</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Ministerio de Educación de Chile; MINEDUC</td>\n",
       "      <td>UCE, MINEDUC</td>\n",
       "      <td>Fernández, Carolina</td>\n",
       "      <td>Jashes, Jessana</td>\n",
       "      <td>Sin información</td>\n",
       "      <td>Interno</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>https://bibliotecadigital.mineduc.cl/bitstream...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Año de publicación Código sugerido  \\\n",
       "0                1999        E99-0000   \n",
       "1                2000        E00-0001   \n",
       "2                2001        E01-0001   \n",
       "3                2001        E01-0002   \n",
       "4                2001        E01-0003   \n",
       "\n",
       "                         Nombre del archivo  \\\n",
       "0               Mercado Laboral en Docencia   \n",
       "1             Evaluación Resultados ENLACES   \n",
       "2   Focalización Becas Liceos Para Todos CC   \n",
       "3  Focalización Becas Liceos Para Todos ECO   \n",
       "4                       OFT Educación Media   \n",
       "\n",
       "                                  Título del estudio Categoría  \\\n",
       "0  Análisis del Mercado de Servicios de Docencia ...  Estudios   \n",
       "1  Diseño de un modelo de evaluación de resultado...  Estudios   \n",
       "2  Focalización de Becas del Programa Liceo para ...  Estudios   \n",
       "3  Focalización de Becas del Programa Liceo para ...  Estudios   \n",
       "4  Objetivos Fundamentales Transversales en la En...  Estudios   \n",
       "\n",
       "  Tipo de documento            Subcategoría   Idioma  Número de páginas  \\\n",
       "0           Informe                Docentes  Español                123   \n",
       "1           Informe                     TIC  Español                 53   \n",
       "2           Informe  Monitoreo y evaluación  Español                 30   \n",
       "3           Informe  Monitoreo y evaluación  Español                 61   \n",
       "4           Informe               Currículo  Español                 61   \n",
       "\n",
       "  Incorpora perspectiva de género  ...  \\\n",
       "0                              No  ...   \n",
       "1                              No  ...   \n",
       "2                              No  ...   \n",
       "3                              No  ...   \n",
       "4                              No  ...   \n",
       "\n",
       "                                 Entidad solicitante  \\\n",
       "0          Ministerio de Educación de Chile; MINEDUC   \n",
       "1  Enlaces; Ministerio de Educación de Chile; MIN...   \n",
       "2          Ministerio de Educación de Chile; MINEDUC   \n",
       "3          Ministerio de Educación de Chile; MINEDUC   \n",
       "4          Ministerio de Educación de Chile; MINEDUC   \n",
       "\n",
       "                         Entidad a cargo del estudio  \\\n",
       "0  Facultad de Ciencias Económicas y Administrati...   \n",
       "1                       Asesorías para el Desarrollo   \n",
       "2                 Departamento de Salud Pública, PUC   \n",
       "3                 Departamento de Salud Pública, PUC   \n",
       "4                                       UCE, MINEDUC   \n",
       "\n",
       "  Investigador u organismo principal               Equipo de investigación  \\\n",
       "0                       Bravo, David  Ruiz-Tagle, Jaime; Sanhueza, Ricardo   \n",
       "1                  Raczynski, Dagmar                    Pavez, M. Angélica   \n",
       "2                Marshall, Guillermo                        Correa, Lorena   \n",
       "3                Marshall, Guillermo                        Correa, Lorena   \n",
       "4                Fernández, Carolina                       Jashes, Jessana   \n",
       "\n",
       "  Número de documento administrativo Tipo de financiamiento Costo del estudio  \\\n",
       "0                    Sin información                Interno                 0   \n",
       "1                    Sin información                Interno                 0   \n",
       "2                    Sin información                Interno                 0   \n",
       "3                    Sin información                Interno                 0   \n",
       "4                    Sin información                Interno                 0   \n",
       "\n",
       "  Base de datos enviada Base pública  \\\n",
       "0                    No           No   \n",
       "1                    No           No   \n",
       "2                    No           No   \n",
       "3                    No           No   \n",
       "4                    No           No   \n",
       "\n",
       "                                                 Url  \n",
       "0  https://bibliotecadigital.mineduc.cl/bitstream...  \n",
       "1  https://bibliotecadigital.mineduc.cl/bitstream...  \n",
       "2  https://bibliotecadigital.mineduc.cl/bitstream...  \n",
       "3  https://bibliotecadigital.mineduc.cl/bitstream...  \n",
       "4  https://bibliotecadigital.mineduc.cl/bitstream...  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Celda 1: Importaciones, Carga de Datos y Configuración Inicial\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import psutil\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import Memory\n",
    "import gradio as gr\n",
    "from IPython.display import display # Importado para display(df.head())\n",
    "\n",
    "# LlamaIndex Core y componentes\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    Settings,\n",
    "    Document\n",
    ")\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.openrouter import OpenRouter\n",
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "\n",
    "# --- 1. Configurar Entorno ---\n",
    "num_cores = psutil.cpu_count(logical=True)\n",
    "os.environ['OMP_NUM_THREADS'] = str(num_cores)\n",
    "os.environ['MKL_NUM_THREADS'] = str(num_cores)\n",
    "print(f\"Librerías importadas. ¡Entorno listo con {num_cores} núcleos disponibles!\")\n",
    "\n",
    "# --- 2. Definir Rutas y Cargar Metadatos ---\n",
    "METADATA_FILE = os.path.join(\"data\", \"metadatos_chatbot_final.csv\")\n",
    "\n",
    "def load_metadata_dataframe(filepath):\n",
    "    \"\"\"Carga los metadatos desde un CSV a un DataFrame de Pandas.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        # Llenamos los valores vacíos con \"No especificado\" para evitar errores\n",
    "        df.fillna(\"No especificado\", inplace=True)\n",
    "        print(\"Metadatos cargados y procesados.\")\n",
    "        display(df.head())\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: No se encontró el archivo de metadatos en la ruta: {filepath}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR al cargar metadatos: {e}.\")\n",
    "        return None\n",
    "\n",
    "# Cargar el DataFrame al inicio\n",
    "df_metadatos = load_metadata_dataframe(METADATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bc27b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clave de API de OpenRouter cargada.\n",
      "Token de Hugging Face (HF_TOKEN) encontrado en el entorno.\n",
      "Configurando el modelo de embeddings con batch size óptimo de 64 para 6 núcleos.\n",
      "Usando Gemini como modelo LLM.\n",
      "\n",
      "Configuración de modelos completada.\n",
      "Uso de memoria actual: 553.79 MB\n"
     ]
    }
   ],
   "source": [
    "# Celda 2: CONFIGURACIÓN OPTIMIZADA DE MODELOS DE IA\n",
    "\n",
    "# Cargar la clave de API desde el archivo .env\n",
    "load_dotenv()\n",
    "if \"OPENROUTER_API_KEY\" in os.environ:\n",
    "    print(\"Clave de API de OpenRouter cargada.\")\n",
    "else:\n",
    "    print(\"¡ADVERTENCIA! No se encontró la clave de API de OpenRouter.\")\n",
    "\n",
    "if \"HF_TOKEN\" in os.environ:\n",
    "    print(\"Token de Hugging Face (HF_TOKEN) encontrado en el entorno.\")\n",
    "else:\n",
    "    print(\"¡ADVERTENCIA! No se encontró el token de Hugging Face.\")\n",
    "\n",
    "# --- Configuración global de LlamaIndex optimizada para CPU ---\n",
    "optimal_batch_size = max(64, num_cores * 8)\n",
    "print(f\"Configurando el modelo de embeddings con batch size óptimo de {optimal_batch_size} para {num_cores} núcleos.\")\n",
    "\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\",\n",
    "    embed_batch_size=optimal_batch_size,\n",
    "    cache_folder=\"./model_cache\",\n",
    "    normalize=True,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Selecciona el proveedor de LLM aquí: \"openrouter\" o \"gemini\"\n",
    "LLM_PROVIDER = \"gemini\"\n",
    "\n",
    "if LLM_PROVIDER == \"gemini\":\n",
    "    Settings.llm = GoogleGenAI(\n",
    "        api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
    "        model=\"gemini-1.5-flash-latest\",\n",
    "        temperature=0.1,\n",
    "    )\n",
    "    print(\"Usando Gemini como modelo LLM.\")\n",
    "else:\n",
    "    Settings.llm = OpenRouter(\n",
    "        model=\"google/gemma-3n-e4b-it:free\",\n",
    "        #model=\"google/gemma-3n-e2b-it:free\",\n",
    "        #model=\"mistralai/mistral-small-3.2-24b-instruct:free\",\n",
    "        #model=\"deepseek/deepseek-chat-v3-0324:free\",\n",
    "        #model=\"deepseek/deepseek-r1-0528:free\",\n",
    "        #model=\"deepseek/deepseek-chat:free\",\n",
    "        #model=\"google/gemini-2.0-flash-exp:free\",\n",
    "        #model=\"mistralai/mistral-nemo:free\",\n",
    "        #model=\"qwen/qwq-32b:free\",\n",
    "        #model=\"microsoft/mai-ds-r1:free\",\n",
    "        #model=\"meta-llama/llama-4-maverick:free\",\n",
    "        temperature=0.1, \n",
    "    )\n",
    "    print(\"Usando OpenRouter como modelo LLM.\")\n",
    "\n",
    "# Función para monitorear uso de memoria\n",
    "def print_memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    memory_info = process.memory_info()\n",
    "    print(f\"Uso de memoria actual: {memory_info.rss / (1024 * 1024):.2f} MB\")\n",
    "\n",
    "print(\"\\nConfiguración de modelos completada.\")\n",
    "print_memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fbfb819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 3: Creación o Carga del Índice Vectorial (con Caching)\n",
    "\n",
    "# 1. Configuramos la ubicación de la caché de joblib\n",
    "CACHE_DIR = \"./joblib_cache\"\n",
    "memory = Memory(CACHE_DIR, verbose=1)\n",
    "\n",
    "# 2. Función para crear el índice (se ejecutará solo si no está en caché)\n",
    "@memory.cache\n",
    "def get_or_create_index(dataframe):\n",
    "    print(\"=\"*50)\n",
    "    print(\"INICIANDO PROCESO DE CREACIÓN DE ÍNDICE (LENTO LA PRIMERA VEZ)...\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if dataframe is None:\n",
    "        print(\"No se puede crear el índice porque el DataFrame es nulo.\")\n",
    "        return None\n",
    "\n",
    "    Settings.node_parser = SentenceSplitter(chunk_size=2048)\n",
    "\n",
    "    def optimize_text_for_embedding(text, max_length=1500):\n",
    "        if not isinstance(text, str): return \"\"\n",
    "        text = text[:max_length]\n",
    "        text = re.sub(r'\\\\s+', ' ', text)\n",
    "        return text.strip()\n",
    "        \n",
    "    print(\"Convirtiendo metadatos en documentos de LlamaIndex...\")\n",
    "    metadata_documents = []\n",
    "    columnas_a_incluir = [\n",
    "        'Año de publicación', 'Código sugerido', 'Nombre del archivo', 'Título del estudio', \n",
    "        'Categoría', 'Tipo de documento', 'Subcategoría', 'Idioma', 'Número de páginas', \n",
    "        'Incorpora perspectiva de género', 'Año de término', 'Lugar de término', \n",
    "        'Palabras clave', 'Objetivo', 'Metodología', 'Resumen', 'Documento público', \n",
    "        'Publicación destacada', 'Publicado', 'Editorial', 'Entidad solicitante',\n",
    "        'Entidad a cargo del estudio', 'Investigador u organismo principal', 'Equipo de investigación', \n",
    "        'Número de documento administrativo', 'Tipo de financiamiento', 'Costo del estudio', \n",
    "        'Base de datos enviada', 'Base pública', 'Url'\n",
    "    ]\n",
    "    columnas_prioritarias = ['Título del estudio', 'Resumen', 'Palabras clave', 'Objetivo', \n",
    "                             'Metodología', 'Investigador u organismo principal']\n",
    "\n",
    "    for index, row in tqdm(dataframe.iterrows(), total=dataframe.shape[0], desc=\"Procesando metadatos\"):\n",
    "        partes_texto = []\n",
    "        for col in columnas_prioritarias:\n",
    "            if col in row and pd.notna(row[col]) and row[col] != \"No especificado\":\n",
    "                texto_optimizado = optimize_text_for_embedding(str(row[col]), 300)\n",
    "                if texto_optimizado:\n",
    "                    partes_texto.append(f\"{col}: {texto_optimizado}\"); partes_texto.append(f\"{col}: {texto_optimizado}\")\n",
    "        \n",
    "        for col in columnas_a_incluir:\n",
    "            if col not in columnas_prioritarias:\n",
    "                if col in row and pd.notna(row[col]) and row[col] != \"No especificado\":\n",
    "                    texto_optimizado = optimize_text_for_embedding(str(row[col]), 200)\n",
    "                    if texto_optimizado:\n",
    "                        partes_texto.append(f\"{col}: {texto_optimizado}\")\n",
    "        \n",
    "        contenido_buscable = \". \".join(partes_texto)\n",
    "        doc = Document(\n",
    "            text=contenido_buscable,\n",
    "            metadata={col: optimize_text_for_embedding(str(row.get(col, '')), 500) for col in columnas_a_incluir}\n",
    "        )\n",
    "        metadata_documents.append(doc)\n",
    "    \n",
    "    print(\"Creando índice vectorial con FAISS...\")\n",
    "    d = len(Settings.embed_model.get_text_embedding(\"test\"))\n",
    "    faiss_index = faiss.IndexFlatL2(d)\n",
    "    vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    \n",
    "    index = VectorStoreIndex.from_documents(\n",
    "        metadata_documents,\n",
    "        storage_context=storage_context,\n",
    "        show_progress=True \n",
    "    )\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"¡ÍNDICE CREADO Y GUARDADO EN CACHÉ EXITOSAMENTE!\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    return index\n",
    "\n",
    "# 3. Llamamos a la función, pasándole el dataframe\n",
    "if 'df_metadatos' in locals() and df_metadatos is not None:\n",
    "    metadata_index = get_or_create_index(df_metadatos)\n",
    "else:\n",
    "    print(\"No se puede crear el índice porque el DataFrame de metadatos no se cargó. Revisa la Celda 1.\")\n",
    "    metadata_index = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633771bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se identificaron 1887 autores únicos para la búsqueda precisa.\n",
      "\n",
      "Lanzando la interfaz de CEMIA...\n",
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Recibida consulta: '¿qué puedes hacer?'\n",
      "Intención detectada por la IA: 'ayuda'\n",
      "Intención detectada por la IA: 'ayuda'\n",
      "--------------------------------------------------\n",
      "Recibida consulta: 'hola'\n",
      "Intención detectada por la IA: 'saludo'\n",
      "Intención detectada por la IA: 'saludo'\n",
      "--------------------------------------------------\n",
      "Recibida consulta: 'estudios sobre brecha de género'\n",
      "Intención detectada por la IA: 'busqueda_por_tema'\n",
      "Intención detectada por la IA: 'busqueda_por_tema'\n",
      "Búsqueda semántica por tema: 'estudios sobre brecha de género'.\n",
      "Extrayendo concepto clave con LLM...\n",
      "Término de búsqueda final: 'brecha de género, desigualdad de género, estudios de género, discriminación de género, participación femenina, representación femenina, techo de cristal'\n"
     ]
    }
   ],
   "source": [
    "# Celda 4: Lógica del Chatbot e Interfaz Gradio\n",
    "\n",
    "if 'metadata_index' not in locals() or metadata_index is None or 'df_metadatos' not in locals() or df_metadatos is None:\n",
    "    print(\"ERROR: El índice o el DataFrame no han sido creados. Por favor, ejecuta las celdas anteriores correctamente.\")\n",
    "else:\n",
    "    # --- Pre-cálculo de autores conocidos ---\n",
    "    autores_principales = set(df_metadatos['Investigador u organismo principal'].str.lower().unique())\n",
    "    autores_equipo_raw = set(df_metadatos['Equipo de investigación'].str.lower().unique())\n",
    "    autores_equipo = set()\n",
    "    for item in autores_equipo_raw:\n",
    "        if isinstance(item, str):\n",
    "            nombres = re.split(r'[;,]', item)\n",
    "            for nombre in nombres:\n",
    "                if nombre.strip():\n",
    "                    autores_equipo.add(nombre.strip())\n",
    "    KNOWN_AUTHORS = autores_principales.union(autores_equipo)\n",
    "    print(f\"Se identificaron {len(KNOWN_AUTHORS)} autores únicos para la búsqueda precisa.\")\n",
    "\n",
    "    # --- GESTOR DE ESTADO DE LA CONVERSACIÓN ---\n",
    "    chat_state = {\"last_query_term\": None, \"last_results\": [], \"last_author_filter\": None, \"current_page\": 0}\n",
    "\n",
    "    # --- Funciones de apoyo ---\n",
    "    def get_relevance_label(score):\n",
    "        if score >= 0.75: return \"Muy Alta\"\n",
    "        elif score >= 0.5: return \"Alta\"\n",
    "        elif score >= 0.25: return \"Media\"\n",
    "        else: return \"Baja\"\n",
    "    \n",
    "    def find_relevance_reason(node_text, search_terms_str):\n",
    "        search_terms = [term.strip() for term in search_terms_str.split(',') if term.strip()]\n",
    "        reasons = []\n",
    "        for term in search_terms:\n",
    "            match = re.search(re.escape(term), node_text, re.IGNORECASE)\n",
    "            if match:\n",
    "                start, end = match.span()\n",
    "                context_start = max(0, start - 50)\n",
    "                context_end = min(len(node_text), end + 70)\n",
    "                context_snippet = node_text[context_start:context_end].strip().replace(match.group(0), f\"**{match.group(0)}**\")\n",
    "                text_before_match = node_text[:start]\n",
    "                metadata_match = re.findall(r\"(\\b[\\w\\s'óáéíúñü]+\\b):\\s\", text_before_match)\n",
    "                metadata_name = metadata_match[-1] if metadata_match else \"Contenido\"\n",
    "                reasons.append(f\"Término '{term}' encontrado en **{metadata_name}** (contexto: *'...{context_snippet}...'*)\\n\")\n",
    "        if not reasons: return f\"Relevancia semántica general con '{search_terms_str}'\"\n",
    "        return \"\".join(reasons)\n",
    "\n",
    "    def search_by_author(author_name):\n",
    "        print(f\"Búsqueda precisa por autor: '{author_name}'.\")\n",
    "        mask = (df_metadatos['Investigador u organismo principal'].str.contains(author_name, case=False, na=False, regex=False) |\n",
    "                df_metadatos['Equipo de investigación'].str.contains(author_name, case=False, na=False, regex=False))\n",
    "        author_hits_df = df_metadatos[mask].copy()\n",
    "        author_hits_df['Año de publicación num'] = pd.to_numeric(author_hits_df['Año de publicación'], errors='coerce').fillna(0)\n",
    "        sorted_hits_df = author_hits_df.sort_values(by='Año de publicación num', ascending=False)\n",
    "        num_docs_encontrados = len(sorted_hits_df)\n",
    "        if num_docs_encontrados == 0: return f\"No he encontrado documentos del autor '{author_name}'. Prueba con otro nombre o solo el apellido.\"\n",
    "        header = f\"He encontrado {num_docs_encontrados} documento(s) del autor '{author_name}', ordenados por año (del más reciente al más antiguo):\\n\\n\"\n",
    "        lista_formateada = []\n",
    "        for i, (index, row) in enumerate(sorted_hits_df.iterrows(), 1):\n",
    "            titulo, autores, ano_str, url = row.get('Título del estudio', 'N/A'), f\"{row.get('Investigador u organismo principal', 'N/A')}, {row.get('Equipo de investigación', 'N/A')}\", str(row.get('Año de publicación', 'N/A')), row.get('Url', 'No disponible')\n",
    "            try: ano = str(int(float(ano_str)))\n",
    "            except (ValueError, TypeError): ano = ano_str\n",
    "            info_doc = (f\"{i}. **Título:** {titulo}\\n   - **Autor(es):** {autores}\\n   - **Año:** {ano}\\n   - **URL:** {url}\")\n",
    "            lista_formateada.append(info_doc)\n",
    "        return header + \"\\n\\n\".join(lista_formateada)\n",
    "\n",
    "    def format_results_page():\n",
    "        total_found, current_page, llm_term = len(chat_state[\"last_results\"]), chat_state[\"current_page\"], chat_state[\"last_query_term\"]\n",
    "        if total_found == 0: return f\"No he encontrado documentos relevantes sobre '{llm_term}'. Por favor, intenta reformular tu búsqueda.\"\n",
    "        MAX_TO_SHOW, start_index = 5, (current_page - 1) * 5\n",
    "        nodes_to_show = chat_state[\"last_results\"][start_index:start_index + MAX_TO_SHOW]\n",
    "        if not nodes_to_show: return f\"No hay más documentos que mostrar sobre '{llm_term}'. Ya estás en la última página.\"\n",
    "        header = \"\"\n",
    "        if current_page == 1:\n",
    "            header = f\"He encontrado un total de {total_found} documentos relevantes sobre '{llm_term}'. Mostrando los {len(nodes_to_show)} más relevantes (página {current_page}):\\n\\n\"\n",
    "        else:\n",
    "            header = f\"Mostrando la página {current_page} de {-(-total_found // MAX_TO_SHOW)} para '{llm_term}' (documentos {start_index + 1}-{start_index + len(nodes_to_show)}):\\n\\n\"\n",
    "        \n",
    "        lista_formateada = []\n",
    "        for i, res in enumerate(nodes_to_show, start=start_index + 1):\n",
    "            metadata, score, reason_text = res['node'].metadata, res['score'], res['reason']\n",
    "            relevance_label, relevance_percentage, url = get_relevance_label(score), f\"{score:.0%}\", metadata.get('Url', 'No disponible')\n",
    "            info_doc = (f\"{i}. **Título:** {metadata.get('Título del estudio', 'N/A')} **(Relevancia: {relevance_label} [{relevance_percentage}])**\\n\"\n",
    "                        f\"   - **Autor(es):** {metadata.get('Investigador u organismo principal', 'N/A')}, {metadata.get('Equipo de investigación', 'N/A')}\\n\"\n",
    "                        f\"   - **Año:** {metadata.get('Año de publicación', 'N/A')}\\n\"\n",
    "                        f\"   - **URL:** {url}\\n\"\n",
    "                        f\"   - ***Motivo:*** *{reason_text}*\")\n",
    "            lista_formateada.append(info_doc)\n",
    "        \n",
    "        footer = \"\\n\\n--- \\n*Para ver más, escribe 'siguiente', 'más' o 'página {current_page + 1}'.*\" if (start_index + MAX_TO_SHOW) < total_found else \"\"\n",
    "        return header + \"\\n\\n\".join(lista_formateada) + footer\n",
    "\n",
    "    def search_by_topic(message):\n",
    "        print(f\"Búsqueda semántica por tema: '{message}'.\")\n",
    "        print(\"Extrayendo concepto clave con LLM...\")\n",
    "        extraction_template = PromptTemplate(\n",
    "            \"Eres un motor de búsqueda semántica. Reescribe la pregunta del usuario en una consulta optimizada (una frase o conceptos clave separados por comas) para encontrar documentos en una base de datos académica.\\n\"\n",
    "            \"Ejemplo 1: 'estudios sobre brecha de genero' -> brecha de género, desigualdad de género en educación\\n\"\n",
    "            \"Ejemplo 2: 'documentos sobre evaluacion docente' -> evaluación docente, desempeño de profesores\\n\"\n",
    "            \"---\\nPregunta original: '{query_str}'\\nConsulta optimizada:\"\n",
    "        )\n",
    "        prompt_final = extraction_template.format(query_str=message)\n",
    "        response = Settings.llm.complete(prompt_final)\n",
    "        llm_term = str(response).strip().lower()\n",
    "        print(f\"Término de búsqueda final: '{llm_term}'\")\n",
    "        \n",
    "        retriever = metadata_index.as_retriever(similarity_top_k=30)\n",
    "        retrieved_nodes = retriever.retrieve(llm_term)\n",
    "        \n",
    "        relevant_results = []\n",
    "        RELEVANCE_THRESHOLD = 0.40\n",
    "        if retrieved_nodes:\n",
    "            all_potential_results = []\n",
    "            for node_with_score in retrieved_nodes:\n",
    "                detailed_reason = find_relevance_reason(node_with_score.node.text, llm_term)\n",
    "                all_potential_results.append({\"node\": node_with_score.node, \"score\": node_with_score.score, \"reason\": detailed_reason})\n",
    "            \n",
    "            all_potential_results.sort(key=lambda x: x['score'], reverse=True)\n",
    "            for result in all_potential_results:\n",
    "                if result[\"score\"] >= RELEVANCE_THRESHOLD:\n",
    "                    relevant_results.append(result)\n",
    "                    \n",
    "        chat_state.update({\"last_query_term\": llm_term, \"last_results\": relevant_results, \"current_page\": 1})\n",
    "        return format_results_page()\n",
    "\n",
    "    # --- ROUTER DE IA Y GESTORES DE INTENCIONES ---\n",
    "    def get_user_intent(user_message):\n",
    "        intent_classifier_prompt = PromptTemplate(\n",
    "            \"Clasifica la intención del usuario en una categoría: 'saludo', 'ayuda', 'chitchat', 'paginacion', 'busqueda_por_autor', 'busqueda_por_tema'.\\n\"\n",
    "            \"Ejemplos:\\n\"\n",
    "            \"Usuario: 'Hola' -> saludo\\n\"\n",
    "            \"Usuario: 'siguiente' -> paginacion\\n\"\n",
    "            \"Usuario: 'trabajos del autor Fernández' -> busqueda_por_autor\\n\"\n",
    "            \"Usuario: 'estudios sobre deserción' -> busqueda_por_tema\\n\"\n",
    "            \"Usuario: 'documentos de Bravo sobre mercado laboral' -> busqueda_por_autor\\n\"\n",
    "            \"Analiza la pregunta y responde SÓLO con la categoría.\\n\\n\"\n",
    "            \"Pregunta: '{query_str}'\\nCategoría:\"\n",
    "        )\n",
    "        prompt = intent_classifier_prompt.format(query_str=user_message)\n",
    "        response = Settings.llm.complete(prompt)\n",
    "        intent = str(response).strip().lower().replace(\" \", \"_\")\n",
    "        print(f\"Intención detectada por la IA: '{intent}'\")\n",
    "        return intent\n",
    "\n",
    "    def extract_author_name(user_message):\n",
    "        name_extractor_prompt = PromptTemplate(\n",
    "            \"Extrae el nombre de autor de la pregunta. Responde SÓLO con el nombre.\\n\"\n",
    "            \"Ejemplo 1: 'trabajos del autor Bravo' -> Bravo\\n\"\n",
    "            \"Ejemplo 2: 'documentos de Carolina Fernández sobre currículo' -> Carolina Fernández\\n\"\n",
    "            \"---\\nPregunta: '{query_str}'\\nNombre del autor:\"\n",
    "        )\n",
    "        prompt = name_extractor_prompt.format(query_str=user_message)\n",
    "        response = Settings.llm.complete(prompt)\n",
    "        author_name = str(response).strip()\n",
    "        print(f\"Nombre de autor extraído por la IA: '{author_name}'\")\n",
    "        return author_name\n",
    "\n",
    "    def handle_chitchat(user_message):\n",
    "        chitchat_prompt = PromptTemplate(\n",
    "            \"Tu nombre es CEMIA, un asistente IA profesional y amable del Centro de Estudios del MINEDUC. \"\n",
    "            \"Responde brevemente a la pregunta conversacional y redirige a tu función principal de buscar documentos.\\n\"\n",
    "            \"Ejemplo:\\nUsuario: 'gracias'\\nRespuesta: ¡De nada! Me alegra poder ayudar. ¿Hay algo más que necesites buscar?\\n\"\n",
    "            \"---\\nPregunta: '{chitchat_query}'\\nRespuesta:\"\n",
    "        )\n",
    "        prompt = chitchat_prompt.format(chitchat_query=user_message)\n",
    "        response = Settings.llm.complete(prompt)\n",
    "        return str(response).strip()\n",
    "\n",
    "    # --- FUNCIÓN PRINCIPAL CON ROUTER DE IA AVANZADO ---\n",
    "    def unified_search(message, history):\n",
    "        print(\"-\" * 50); print(f\"Recibida consulta: '{message}'\")\n",
    "        \n",
    "        # Reiniciar estado para nuevas búsquedas, pero no para paginación o charla\n",
    "        if not any(keyword in message.lower() for keyword in ['siguiente', 'más', 'pagina', 'página']):\n",
    "             if get_user_intent(message) not in ['chitchat', 'saludo', 'ayuda']:\n",
    "                chat_state.clear()\n",
    "                chat_state.update({\"last_query_term\": None, \"last_results\": [], \"current_page\": 0})\n",
    "        \n",
    "        intent = get_user_intent(message)\n",
    "\n",
    "        if intent == \"saludo\":\n",
    "            return \"¡Hola! Soy CEMIA, tu asistente de IA para el Centro de Estudios del MINEDUC. Puedes preguntarme por temas o autores. ¿En qué puedo asistirte hoy?\"\n",
    "\n",
    "        elif intent == \"ayuda\":\n",
    "            return (\"¡Claro! Soy CEMIA y te ayudo a buscar documentos.\\n\"\n",
    "                    \"**1. Búsqueda por Tema:** `Estudios sobre retención en primer año`\\n\"\n",
    "                    \"**2. Búsqueda por Autor:** `trabajos del autor Fernández`\\n\"\n",
    "                    \"**3. Búsqueda Combinada:** `documentos de Bravo sobre mercado laboral` (priorizará al autor)\\n\"\n",
    "                    \"**4. Navegación:** `siguiente` o `página 3` para ver más resultados.\\n\"\n",
    "                    \"¿Qué te gustaría buscar?\")\n",
    "\n",
    "        elif intent == \"chitchat\":\n",
    "            return handle_chitchat(message)\n",
    "\n",
    "        elif intent == \"paginacion\":\n",
    "            if not chat_state[\"last_results\"]: return \"Primero necesitas hacer una búsqueda para poder ver más resultados.\"\n",
    "            page_match = re.search(r\"p[aá]gina\\s+(\\d+)\", message.strip().lower())\n",
    "            chat_state[\"current_page\"] = int(page_match.group(1)) if page_match else chat_state[\"current_page\"] + 1\n",
    "            return format_results_page()\n",
    "        \n",
    "        elif intent == \"busqueda_por_autor\":\n",
    "            author_name = extract_author_name(message)\n",
    "            return search_by_author(author_name)\n",
    "\n",
    "        else: # 'busqueda_por_tema' o por defecto\n",
    "            return search_by_topic(message)\n",
    "\n",
    "    # --- Creación de la Interfaz de Gradio ---\n",
    "    chat_interface = gr.ChatInterface(\n",
    "        fn=unified_search,\n",
    "        chatbot=gr.Chatbot(height=500, type=\"messages\"),\n",
    "        type=\"messages\",\n",
    "        title=\"CEMIA (Asistente IA del Centro de Estudios)\",\n",
    "        description=\"Busca por tema o autor. El chatbot recordará tu última búsqueda para que puedas pedirle 'siguiente' o 'página 2'.\",\n",
    "        examples=[\"¿qué puedes hacer?\", \"estudios sobre brecha de género\", \"trabajos de Bravo\", \"siguiente\"],\n",
    "        theme=\"default\",\n",
    "    )\n",
    "\n",
    "    print(\"\\nLanzando la interfaz de CEMIA...\")\n",
    "    chat_interface.launch(inline=True, share=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
